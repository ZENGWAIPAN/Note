{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98462,"databundleVersionId":11751604,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MOAI 2025 Training \n\n本題目是 MOAI 2025 的訓練題目\n\n你將使用 PyTorch 來構建一個卷積神經網絡（CNN）模型，用於識別手寫數字，請按照以下步驟完成任務。\n\n第一段代碼中的 TaskGrader 是一個評分器，請不要修改。可以點擊代碼塊中左側的深色部分將代碼摺疊。","metadata":{}},{"cell_type":"code","source":"# 此部分為評分器，請勿編輯此單元格\n\nimport torch\nimport pandas as pd\n\n\nclass TaskGrader:\n    def __init__(self):\n        self.q1_1_pass = False\n        self.q1_2_pass = False\n        self.q1_3_pass = False\n\n        self.q2_1_pass = False\n        self.q2_2_pass = False\n        self.q2_3_pass = False\n        self.q2_4_pass = False\n        self.q2_5_pass = False\n\n        self.q3_1_pass = False\n        self.q3_2_pass = False\n\n    def q1_1_check(self, images_raw, labels_raw):\n        try:\n            assert isinstance(images_raw, torch.Tensor), \"圖片應該是 torch.Tensor 類型\"\n            assert images_raw.shape == (60000, 28, 28), f\"圖片維度大小應該是 (60000, 28, 28)，現在是{images_raw.shape}\"\n\n            assert isinstance(labels_raw, pd.DataFrame), \"標籤應該是 pandas DataFrame 類型\"\n            assert len(labels_raw) == 60000, f\"標籤應該有 60000 行，現在是 {len(labels_raw)}\"\n        except AssertionError as e:\n            print(\"Q1.1未通過:\", str(e))\n            return\n\n        self.q1_1_pass = True\n        print(\"Q1.1通過 (5分)\")\n\n    def q1_2_check(self, images, labels):\n        try:\n            assert isinstance(images, torch.Tensor), \"歸一化後的圖像必須是 torch.Tensor 類型\"\n            assert isinstance(labels, torch.Tensor), \"標籤必須是 torch.Tensor 類型\"\n\n            assert -0.1 < images.mean() < 0.1, f\"歸一化圖像的均值應接近0，現在是{images.mean()}\"\n            assert 0.9 < images.std() < 1.1, f\"歸一化圖像的標準差應接近1，現在是{images.std()}\"\n        except AssertionError as e:\n            print(\"Q1.2未通過:\", str(e))\n            return\n\n        self.q1_2_pass = True\n        print(\"Q1.2通過 (5分)\")\n\n    def q1_3_check(self, train_dataset, val_dataset):\n        try:\n            total_size = len(train_dataset) + len(val_dataset)\n            train_ratio = len(train_dataset) / total_size\n\n            assert 0.79 <= train_ratio <= 0.81, f\"訓練-驗證集分割應為8:2，現在是{train_ratio:.2f}:{1 - train_ratio:.2f}\"\n        except AssertionError as e:\n            print(\"Q1.3未通過:\", str(e))\n            return\n\n        self.q1_3_pass = True\n        print(\"Q1.3通過 (5分)\")\n\n    def q2_check(self, model):\n        try:\n            for name, module in model.named_modules():\n                if isinstance(module, torch.nn.Conv2d):\n                    self.q2_1_pass = True\n                elif isinstance(module, torch.nn.MaxPool2d):\n                    self.q2_2_pass = True\n                elif any(\n                    isinstance(module, act)\n                    for act in [\n                        torch.nn.ReLU,\n                        torch.nn.Sigmoid,\n                        torch.nn.Tanh,\n                        torch.nn.ELU,\n                        torch.nn.LeakyReLU,\n                        torch.nn.PReLU,\n                    ]\n                ):\n                    self.q2_3_pass = True\n                elif isinstance(module, torch.nn.Linear):\n                    if module.out_features == 10:\n                        self.q2_4_pass = True\n\n            x = torch.randn(1, 28, 28).to(next(model.parameters()).device)\n            output = model(x)\n            if output.shape[1] == 10:\n                self.q2_5_pass = True\n\n        except Exception:\n            pass\n\n        checks = [\n            (self.q2_1_pass, \"Q2.1\", \"模型應包含卷積層\", 2),\n            (self.q2_2_pass, \"Q2.2\", \"模型應包含池化層\", 2),\n            (self.q2_3_pass, \"Q2.3\", \"模型應包含激活函數\", 2),\n            (self.q2_4_pass, \"Q2.4\", \"模型應包含輸出層\", 2),\n            (self.q2_5_pass, \"Q2.5\", \"未能成功定義前向傳播，輸出分類結果\", 7),\n        ]\n\n        for check in checks:\n            if not check[0]:\n                print(f\"{check[1]}未通過: {check[2]}\")\n            else:\n                print(f\"{check[1]}通過 ({check[3]}分)\")\n\n    def q3_1_check(self, criterion, optimizer):\n        try:\n            valid_loss_fns = [\n                torch.nn.CrossEntropyLoss,\n                torch.nn.NLLLoss,\n                torch.nn.MSELoss,\n                torch.nn.L1Loss,\n                torch.nn.SmoothL1Loss,\n                torch.nn.HuberLoss,\n                torch.nn.SoftMarginLoss,\n                torch.nn.MultiLabelMarginLoss,\n                torch.nn.MultiLabelSoftMarginLoss,\n            ]\n\n            valid_optimizers = [\n                torch.optim.SGD,\n                torch.optim.Adam,\n                torch.optim.RMSprop,\n                torch.optim.Adagrad,\n                torch.optim.Adadelta,\n                torch.optim.Adamax,\n                torch.optim.AdamW,\n                torch.optim.SparseAdam,\n                torch.optim.ASGD,\n                torch.optim.Rprop,\n                torch.optim.LBFGS,\n                torch.optim.NAdam,\n            ]\n\n            is_valid_loss = any(isinstance(criterion, loss_fn) for loss_fn in valid_loss_fns)\n            is_valid_optimizer = any(isinstance(optimizer, opt) for opt in valid_optimizers)\n\n            assert is_valid_loss, \"必須使用有效的損失函數 (CrossEntropyLoss, NLLLoss, MSELoss 等)\"\n            assert is_valid_optimizer, \"必須使用有效的優化器 (SGD, Adam, RMSprop 等)\"\n\n        except Exception as e:\n            print(\"Q3.1未通過:\", str(e))\n            return\n\n        self.q3_1_pass = True\n        print(\"Q3.1通過 (5分)\")\n\n    def q3_2_check(self, train_losses, val_losses, train_accs, val_accs):\n        try:\n            assert len(train_losses) >= 5, f\"應至少訓練5個週期，目前{len(train_losses)}\"\n            assert len(val_losses) >= 5, f\"應至少驗證5個週期，目前{len(val_losses)}\"\n            assert len(train_accs) >= 5, f\"應至少記錄5個週期的訓練準確率，目前{len(train_accs)}\"\n            assert len(val_accs) >= 5, f\"應至少記錄5個週期的驗證準確率，目前{len(val_accs)}\"\n\n            assert train_losses[0] > train_losses[-1], \"訓練損失應隨着週期減少\"\n\n            assert train_accs[-1] > 0.5, f\"最終訓練準確率應更高，目前{train_accs[-1]:.2f}\"\n            assert val_accs[-1] > 0.5, f\"最終驗證準確率應更高，目前{val_accs[-1]:.2f}\"\n\n        except Exception as e:\n            print(\"Q3.2未通過:\", str(e))\n            return\n\n        self.q3_2_pass = True\n        print(\"Q3.2通過 (15分)\")\n\n\ntask_grader = TaskGrader()\n\n# 此部分為評分器，請勿編輯此單元格","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:29.073702Z","iopub.execute_input":"2025-05-10T16:43:29.074397Z","iopub.status.idle":"2025-05-10T16:43:29.091189Z","shell.execute_reply.started":"2025-05-10T16:43:29.074373Z","shell.execute_reply":"2025-05-10T16:43:29.090418Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 小題 1：數據讀取與預處理 (15 分)\n\n數據集包括以下內容\n\n- 訓練圖像數據：train_images.pt (shape: [60000, 28, 28])\n- 訓練標籤數據：train_labels.csv\n- 測試圖像數據：test_images.pt (shape: [10000, 28, 28])\n\n其中，訓練數據集提供圖像和標籤，測試數據集只提供圖像，不提供標籤\n\n**本題目要求完成以下內容**\n\n1. 讀取數據集圖片和標籤 (5分)\n2. 將數據集按 **8:2** 的比例劃分為訓練集和驗證集。 (5分)\n3. 將圖像數據歸一化並轉換為 Tensor。 (5分)","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, Subset\n\n# TODO: 讀取數據集，'train-images.pt' 和 'train-labels.csv'\nimages_raw = torch.load(\"/kaggle/input/moai-2025-training/train_images.pt\", weights_only=True)\nlabels_raw = pd.read_csv(\"/kaggle/input/moai-2025-training/train_labels.csv\")\n\n# TODO: 歸一化數據集並轉換為 torch.Tensor\nimages_raw = images_raw.float()\nimg_mean = images_raw.mean()\nimg_std = images_raw.std()\nimages = (images_raw - img_mean) / (img_std + 1e-8)\n\nimages = images.unsqueeze(1)\n\n\nlabels = torch.tensor(labels_raw['label'].values, dtype=torch.long)\n\n# TODO: 創建數據集，並按照 8:2 劃分成訓練集和驗證集\nvalid_ratio = 0.2\ndataset = torch.utils.data.TensorDataset(images, labels)\n\ndataset_size = len(dataset)\nindices = list(range(dataset_size))\ntrain_indices, valid_indices = train_test_split(indices, test_size=0.2, random_state=666)\ntrain_dataset, val_dataset = Subset(dataset, train_indices), Subset(dataset, valid_indices)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:34.619491Z","iopub.execute_input":"2025-05-10T16:43:34.620263Z","iopub.status.idle":"2025-05-10T16:43:35.917743Z","shell.execute_reply.started":"2025-05-10T16:43:34.620236Z","shell.execute_reply":"2025-05-10T16:43:35.916992Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 以下代碼執行後可以判斷你的作答是否正確，請勿修改\ntask_grader.q1_1_check(images_raw, labels_raw)\ntask_grader.q1_2_check(images, labels)\ntask_grader.q1_3_check(train_dataset, val_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:39.057346Z","iopub.execute_input":"2025-05-10T16:43:39.058046Z","iopub.status.idle":"2025-05-10T16:43:39.117822Z","shell.execute_reply.started":"2025-05-10T16:43:39.058014Z","shell.execute_reply":"2025-05-10T16:43:39.116941Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 可視化\n\n以下是一段將數據集進行可視化的代碼，如果前面的代碼編寫正確，會顯示兩行的圖片，第一行是訓練集，第二行是驗證集","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\ndef visualize_samples(loader, title):\n    images, labels = next(iter(loader))\n    images = images[:5]\n    labels = labels[:5]\n    \n    plt.figure(figsize=(15, 3))\n    plt.suptitle(title, fontsize=16)\n    \n    for i in range(5):\n        plt.subplot(1, 5, i+1)\n        img = images[i].squeeze()\n        plt.imshow(img.numpy(), cmap='gray' if img.dim() == 2 else None)\n        plt.title(f\"Label: {labels[i].item()}\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# 可視化訓練集樣本\nvisualize_samples(train_loader, \"Training set\")\n\n# 可視化驗證集樣本\nvisualize_samples(val_loader, \"Validation set\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:41.709681Z","iopub.execute_input":"2025-05-10T16:43:41.710425Z","iopub.status.idle":"2025-05-10T16:43:42.360729Z","shell.execute_reply.started":"2025-05-10T16:43:41.710398Z","shell.execute_reply":"2025-05-10T16:43:42.360063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 小題 2：構建 CNN 模型 (15 分)\n\n定義一個簡單的 CNN 模型，滿足以下條件：\n\n1. 至少包含兩個卷積層 (`nn.Conv2d`) (2分)\n2. 至少包含兩個池化層 (`nn.MaxPool2d`) (2分)\n3. 使用激活函數 (`nn.ReLU`, `nn.Sigmoid`, `nn.Tanh`, `nn.ELU`, `nn.LeakyReLU`, `nn.PreLU` 等) (2分)\n4. 定義輸出層，輸出一個 10 維向量 (對應 10 個類別) (2分)\n5. 定義前向傳播，將以上所有網絡層連接（7分）\n","metadata":{}},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # TODO: 定義網絡層\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=0)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.fc_input_features = 64 * 5 * 5\n        self.fc1 = nn.Linear(in_features=self.fc_input_features, out_features=128)\n        self.relu3 = nn.ReLU()\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc2 = nn.Linear(in_features=128, out_features=10)\n        \n        \n    def forward(self, x):\n        # TODO: 定義前向傳播\n\n        if x.dim() == 3:\n            x = x.unsqueeze(1)\n        # 第一個卷積塊\n        x = self.conv1(x) # (Batch, 1, 28, 28) -> (Batch, 32, 26, 26)\n        x = self.bn1(x)   # (Batch, 32, 26, 26) -> (Batch, 32, 26, 26)\n        x = self.relu1(x) # (Batch, 32, 26, 26) -> (Batch, 32, 26, 26)\n        x = self.pool1(x) # (Batch, 32, 26, 26) -> (Batch, 32, 13, 13)\n\n        # 第二個卷積塊\n        x = self.conv2(x) # (Batch, 32, 13, 13) -> (Batch, 64, 11, 11)\n        x = self.bn2(x)   # (Batch, 64, 11, 11) -> (Batch, 64, 11, 11)\n        x = self.relu2(x) # (Batch, 64, 11, 11) -> (Batch, 64, 11, 11)\n        x = self.pool2(x) # (Batch, 64, 11, 11) -> (Batch, 64, 5, 5)\n\n        # 展平操作: 將特徵圖展平為一維向量\n        # view() 改變張量的形狀，-1 表示由 PyTorch 自動計算該維度的大小\n        # x.size(0) 是 Batch Size\n        x = x.view(-1, self.fc_input_features) # (Batch, 64, 5, 5) -> (Batch, 1600)\n\n        # 全連接層塊\n        x = self.fc1(x)    # (Batch, 1600) -> (Batch, 128)\n        x = self.relu3(x)  # (Batch, 128) -> (Batch, 128)\n        x = self.dropout(x)# (Batch, 128) -> (Batch, 128) (在訓練時生效)\n\n        # 輸出層\n        x = self.fc2(x)    # (Batch, 128) -> (Batch, 10)\n\n        # 對於分類任務，通常最後一層不加激活函數（如 Softmax），\n        # 因為損失函數如 CrossEntropyLoss 會自動包含 Softmax 操作。\n        # 返回的是每個類別的對數幾率 (logits)\n        return x\n        \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CNN().to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:47.186731Z","iopub.execute_input":"2025-05-10T16:43:47.187334Z","iopub.status.idle":"2025-05-10T16:43:47.422783Z","shell.execute_reply.started":"2025-05-10T16:43:47.187311Z","shell.execute_reply":"2025-05-10T16:43:47.422044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 以下代碼執行後可以判斷你的作答是否正確，請勿修改\n\ntask_grader.q2_check(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:43:51.430769Z","iopub.execute_input":"2025-05-10T16:43:51.431463Z","iopub.status.idle":"2025-05-10T16:43:52.058592Z","shell.execute_reply.started":"2025-05-10T16:43:51.431431Z","shell.execute_reply":"2025-05-10T16:43:52.057954Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 小題 3：訓練模型 (20 分)\n\n1. 選擇損失函數 (`MSELoss`, `CrossEntropyLoss` 等) (2分)\n2. 選擇優化器（`SGD`, `Adam` 等），並設置學習率。 (3分)\n3. 模型訓練**至少** 5 個 epoch，並在每個 epoch 結束時分別打印訓練集和驗證集的損失函數和準確率。 (15分)\n","metadata":{}},{"cell_type":"code","source":"# TODO: 定義損失函數和優化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrain_losses = []\ntrain_accs = []\nval_losses = []\nval_accs = []\n\nfor epoch in range(30):\n    # TODO: 訓練循環\n    model.train()\n    running_loss = 0.0\n    running_correct = 0\n    running_total = 0\n    for batch_idx, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        train_loss = loss.item() # .item() 獲取標量值\n\n        # 計算當前 batch 的準確率\n        _, predicted = torch.max(outputs.data, 1) # 獲取預測類別的索引\n        total = labels.size(0) # 當前 batch 的大小\n        correct = (predicted == labels).sum().item() # 當前 batch 中正確的預測數量\n        train_acc = correct / total\n        \n        # 以下是記錄損失函數和準確率的代碼，不用修改\n        if batch_idx % 50 == 0:\n            train_losses.append(train_loss)\n            train_accs.append(train_acc)\n            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc * 100:.2f}%\")\n    \n    # TODO: 驗證循環\n    model.eval()\n    val_running_loss = 0.0 # 累計整個驗證集的損失\n    val_correct = 0      # 累計整個驗證集正確的預測數量\n    val_total = 0        # 累計整個驗證集的樣本數量\n    with torch.no_grad():\n        for images, labels in val_loader:\n            \n            images = images.to(device)\n            labels = labels.to(device)\n\n            # 前向傳播\n            outputs = model(images)\n\n            # 計算損失\n            loss = criterion(outputs, labels)\n\n            # 累計損失 (乘以 batch size 因為 loss 是平均值)\n            val_running_loss += loss.item() * images.size(0)\n\n            # 計算準確率\n            _, predicted = torch.max(outputs.data, 1) # 獲取預測類別的索引\n            val_total += labels.size(0) # 累加當前 batch 的大小到總樣本數\n            val_correct += (predicted == labels).sum().item() # 累加正確的預測數量\n    val_loss = val_running_loss / val_total\n    val_acc = val_correct / val_total\n    # 以下是記錄損失函數和準確率的代碼，不用修改 \n    val_accs.append(val_acc)\n    val_losses.append(val_loss)\n    print(f\"Epoch {epoch+1}, Val Loss: {val_loss}, Val Accuracy: {val_acc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:44:28.191162Z","iopub.execute_input":"2025-05-10T16:44:28.191556Z","iopub.status.idle":"2025-05-10T16:45:20.196754Z","shell.execute_reply.started":"2025-05-10T16:44:28.191537Z","shell.execute_reply":"2025-05-10T16:45:20.195840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 以下代碼執行後可以判斷你的作答是否正確，請勿修改\n\ntask_grader.q3_1_check(criterion, optimizer)\ntask_grader.q3_2_check(train_losses, val_losses, train_accs, val_accs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:45:29.859449Z","iopub.execute_input":"2025-05-10T16:45:29.860192Z","iopub.status.idle":"2025-05-10T16:45:29.864365Z","shell.execute_reply.started":"2025-05-10T16:45:29.860168Z","shell.execute_reply":"2025-05-10T16:45:29.863663Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 可視化\n\n以下是一段將數據集進行可視化的代碼，如果前面的代碼編寫正確，會顯示一行圖片，並顯示模型識別出該圖片是哪一個數字","metadata":{}},{"cell_type":"code","source":"def visualize_predictions(loader, model, title):\n    images, true_labels = next(iter(loader))\n    images = images.to(device)\n    \n    model.eval()\n    with torch.no_grad():\n        outputs = model(images)\n        pred_probs = torch.softmax(outputs, dim=1)\n        pred_labels = outputs.argmax(dim=1)\n    \n    images = images[:5].cpu()\n    true_labels = true_labels[:5]\n    pred_labels = pred_labels[:5].cpu()\n    pred_probs = pred_probs[:5].cpu()\n    \n    plt.figure(figsize=(15, 3))\n    plt.suptitle(title, fontsize=16)\n    \n    for i in range(5):\n        plt.subplot(1, 5, i+1)\n        img = images[i].squeeze()\n        \n        plt.imshow(img.numpy(), cmap='gray' if img.dim() == 2 else None)\n        pred_prob = pred_probs[i][pred_labels[i]].item()\n        plt.title(f\"Prediction: {pred_labels[i].item()}, Answer: {true_labels[i].item()}\", \n                 color='green' if pred_labels[i].item() == true_labels[i].item() else 'red')\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\nvisualize_predictions(val_loader, model, \"Predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:45:37.022990Z","iopub.execute_input":"2025-05-10T16:45:37.023257Z","iopub.status.idle":"2025-05-10T16:45:37.353567Z","shell.execute_reply.started":"2025-05-10T16:45:37.023238Z","shell.execute_reply":"2025-05-10T16:45:37.352924Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 提交\n\n以下代碼會生成一個 `submission.csv`，選手只需要在右側菜單中選擇 `Submit to competition > Submit` 就可以完成提交","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\n\ntest_images = torch.load('/kaggle/input/moai-2025-training/test_images.pt', weights_only=True)\n# TODO: 按照前面的方法歸一化\ntest_images = test_images.float()\nmean = test_images.mean()\nstd = test_images.std()\ntest_images = (test_images - mean) / (std + 1e-8)\n\ntest_images = test_images.unsqueeze(1)\n\nmodel.eval()\nwith torch.no_grad():\n    test_images = test_images.to(device)\n    outputs = model(test_images)\n    predictions = outputs.argmax(dim=1)\n\ndf_test = pd.DataFrame({\"label\": predictions.cpu().numpy()})\ndf_test.to_csv(\"submission.csv\", index_label=\"id\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-10T16:49:20.865474Z","iopub.execute_input":"2025-05-10T16:49:20.866186Z","iopub.status.idle":"2025-05-10T16:49:20.986404Z","shell.execute_reply.started":"2025-05-10T16:49:20.866166Z","shell.execute_reply":"2025-05-10T16:49:20.985845Z"}},"outputs":[],"execution_count":null}]}